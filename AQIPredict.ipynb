{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = 'city_day.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop AQI_Bucket column\n",
    "df_mod0 = df.drop(columns=['AQI_Bucket'])\n",
    "print(df_mod0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any NaN AQI values\n",
    "df_mod1 = df_mod0.copy()\n",
    "df_mod1 = df_mod1.dropna(subset=['AQI'])\n",
    "print(df_mod1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop City\n",
    "df_mod2 = df_mod1.copy()\n",
    "columns_to_drop = ['City']\n",
    "df_mod2.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df_mod2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation to address NaN pollutant values\n",
    "columns_to_fill = df_mod2.select_dtypes(include=np.number).columns.difference(['AQI'])\n",
    "df_mod3 = df_mod2.copy()\n",
    "df_mod3[columns_to_fill] = df_mod2[columns_to_fill].interpolate(method='linear', limit_area='inside', limit=2)\n",
    "df_mod3[columns_to_fill] = df_mod3[columns_to_fill].fillna(df[columns_to_fill].mean())\n",
    "\n",
    "print(df_mod3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Fraction of Type of Pollutant (UNUSED)\n",
    "\"\"\" df_mod4 = df_mod3.copy()\n",
    "df_mod4['Sum_Part_Matter'] = df_mod4['PM2.5'] + df_mod4['PM10']\n",
    "df_mod4['Sum_Gaseous'] = df_mod4[['NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3']].sum(axis=1)\n",
    "df_mod4['Sum_VOC'] = df_mod4[['Benzene', 'Toluene', 'Xylene']].sum(axis=1)\n",
    "\n",
    "df_mod4['Total_Sum'] = df_mod4.iloc[:, 2:-3].sum(axis=1) \n",
    "df_mod4['Fraction_Part_Matter'] = df_mod4['Sum_Part_Matter'] / df_mod4['Total_Sum']\n",
    "df_mod4['Fraction_Gaseous'] = df_mod4['Sum_Gaseous'] / df_mod4['Total_Sum']\n",
    "df_mod4['Fraction_VOC'] = df_mod4['Sum_VOC'] / df_mod4['Total_Sum']\n",
    "fraction_columns = ['Fraction_Part_Matter', 'Fraction_Gaseous', 'Fraction_VOC']\n",
    "df_mod4[fraction_columns] = df_mod4[fraction_columns].div(df_mod4[fraction_columns].sum(axis=1), axis=0)\n",
    "\n",
    "print(df_mod4) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: Season\n",
    "df_mod4 = df_mod3.copy()\n",
    "df_mod4['Date'] = pd.to_datetime(df_mod4['Date'])\n",
    "\n",
    "winter_range = ((df_mod4['Date'].dt.month >= 12) | (df_mod4['Date'].dt.month <= 3))\n",
    "pre_monsoon_range = (df_mod4['Date'].dt.month >= 4) & (df_mod4['Date'].dt.month <= 6)\n",
    "monsoon_range = (df_mod4['Date'].dt.month >= 7) & (df_mod4['Date'].dt.month <= 9)\n",
    "post_monsoon_range = (df_mod4['Date'].dt.month >= 10) & (df_mod4['Date'].dt.month <= 11)\n",
    "\n",
    "df_mod4.loc[winter_range, 'Season'] = 1\n",
    "df_mod4.loc[pre_monsoon_range, 'Season'] = 2\n",
    "df_mod4.loc[monsoon_range, 'Season'] = 3\n",
    "df_mod4.loc[post_monsoon_range, 'Season'] = 4\n",
    "\n",
    "print(df_mod4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Date\n",
    "df_mod5 = df_mod4.copy()\n",
    "df_mod5 = df_mod5.drop(columns=['Date'])\n",
    "\n",
    "print(df_mod5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the columns\n",
    "df_mod6 = df_mod5.copy()\n",
    "new_order = [\n",
    "    'Season', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene',\n",
    "    'Toluene', 'Xylene', 'AQI']\n",
    "df_mod6 = df_mod6.reindex(columns=new_order)\n",
    "\n",
    "print(df_mod6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final dataset to csv for visualization purposes\n",
    "data = df_mod6.copy()\n",
    "data.to_csv('final_data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train = data.drop(columns=['AQI'])\n",
    "y_train = data['AQI']\n",
    "\n",
    "X_val = data.drop(columns=['AQI'])\n",
    "y_val = data['AQI']\n",
    "\n",
    "X_test = data.drop(columns=['AQI'])\n",
    "y_test = data['AQI']\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape) \n",
    "\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_val = np.asarray(X_val).astype('float32')\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model 1\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units=64, input_shape=(13, 1)),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=20, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model 2\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(units=128, return_sequences=True, input_shape=(13, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(units=64, return_sequences=True),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.LSTM(units=32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1,)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train, y_train, epochs=80, batch_size=128, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loss\n",
    "validation_loss = lstm_model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {validation_loss}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE, MAR, and R-squared values\n",
    "predictions = lstm_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\") \n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error (MAE) on Test Data:\", mae)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared (R²) Score on Test Data:\", r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rate as a percentage\n",
    "predictions_reshaped = np.reshape(predictions, (-1, 1))\n",
    "y_test_reshaped = np.reshape(y_test, (-1, 1))\n",
    "differences = abs(predictions_reshaped - y_test_reshaped)\n",
    "successful_predictions = np.sum(differences <= 30)\n",
    "total_predictions = len(predictions)\n",
    "success_rate = (successful_predictions / total_predictions) * 100\n",
    "\n",
    "print(\"Percentage success rate:\", success_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model 1\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(13, 1)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=1) \n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train, y_train, epochs=20, batch_size=20, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model 2\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(13, 1)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(units=128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units=1) \n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='mean_squared_error') \n",
    "cnn_model.fit(X_train, y_train, epochs=300, batch_size=128, validation_data=(X_val, y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loss\n",
    "validation_loss = cnn_model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {validation_loss}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE, MAR, and R-squared values\n",
    "predictions = cnn_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error on Test Set: {mse}\") \n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"Mean Absolute Error (MAE) on Test Data:\", mae)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared (R²) Score on Test Data:\", r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rate as a percentage\n",
    "predictions_reshaped = np.reshape(predictions, (-1, 1))\n",
    "y_test_reshaped = np.reshape(y_test, (-1, 1))\n",
    "differences = abs(predictions_reshaped - y_test_reshaped)\n",
    "successful_predictions = np.sum(differences <= 30)\n",
    "total_predictions = len(predictions)\n",
    "success_rate = (successful_predictions / total_predictions) * 100\n",
    "\n",
    "print(\"Percentage success rate:\", success_rate) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
